# End to end tests

## Overview

End to end tests mount full architecture of services and run scenarios on them. 

- The folder tests/architecture define some docker-compose architectures
- The folder tests/tests define some user scenarios
- the file architectures.json define which scenario to run on each architecture

Before all, the images are built with the last version of the code by the "build.sh" script.

For each couple (scenario, architecture), all the services are brought up. The scenario is run on a special image "runner" inside the docker network. Then the architecture is completely removed before the next one.

This orchestration is done buy the `build_and_test.sh` script.

## Architectures

Architectures can contains the services: 

- A Gitolite instance
- An nginx proxy
- A LFS server (with several different starting commands)
- A Minio server
- A Postgres database
- A runner container

The following architectures are defined:

- `default`: Gitolite + Nginx + LFS + Minio + runner. The LFS server is started with the `signer sbs` command. The LFS is behind the proxy, but not the Minio server, so links are signed directly to `bucket:9000`
- `minio_behind_proxy`: Similar to `default`, but the Minio server is behind the proxy, so links are signed to `proxy`
- `custom_signing` have the same services, but is run with the `signer sbs` command. The LFS is behind the proxy, and the minio server is not accessed directly, so links are signed to `proxy` and passed to the LFS server
- `locks` have an additional Postgres database and the LFS server is started with the `signer sbs locks pg` command. The LFS is behind the proxy. Links are signed to `bucket:9000`. 
- `server-proxy-fs` only have Gitolite, Nginx, LFS and the runner. The objects are stored in the LFS container. The LFS is behind the proxy. Links are signed to `proxy` and passed down to LFS. 
- `server-proxy-fs-locks-pg` is the same, but with an additional postgres database to test locks.

## Scenarios

### Scenario 1: Gitolite Repository Setup and Modification

This test scenario focuses on cloning the Gitolite-admin repository, modifying the Gitolite configuration, adding a new repository, and verifying the changes through cloning and committing in different repositories.

1. Clone the Gitolite-admin repository with three retries.
2. Navigate to the cloned repository and list its contents.
3. Verify the existence of the 'conf' and 'keydir' folders.
4. Verify the content of the 'conf/gitolite.conf' file, ensuring the presence of specific repository configurations.
5. Add a new repository ('test-repo') to the 'conf/gitolite.conf' file.
6. Commit and push the changes made to the 'conf/gitolite.conf' file.
7. Go up one level and clone the newly added repository ('test-repo').
8. Navigate into the cloned 'test-repo' repository and list its contents.
9. Create a new file ('test.txt'), add it to the repository, and commit the changes.
10. Push the changes to the 'test-repo' repository.
11. Go up one level and clone the 'test-repo' repository into a different folder ('test-repo-2').
12. Navigate into the cloned 'test-repo-2' repository and list its contents.
13. Verify the presence of the 'test.txt' file in the 'test-repo-2' repository.
14. Confirm that the repository is on the 'main' branch in both 'test-repo' and 'test-repo-2' repositories.

### Scenario 2: Git LFS Authentication and Handling Invalid Inputs

This test scenario involves running the Git LFS authentication command and validating its behavior for both valid and invalid inputs.

1. Run the Git LFS authentication command
2. Run the Git LFS authentication command with a ref specified
3. For invalid inputs, expect the git-lfs-authenticate command to fail

### Scenario 3: Object Transfer Endpoints Validation

This test scenario involves validating various scenarios related to object transfer endpoints, including successful access, token usage, error handling, and unsupported transfer scenarios.

1. Successful access to the upload batch endpoint, ensuring the correct response with the expected transfer details and HTTP status.
2. Successful access to the download batch endpoint using the upload token, verifying the response contains the expected transfer details and HTTP status.
3. Successful access to the download batch endpoint using the download token, ensuring the response includes the expected transfer details and HTTP status.
4. Attempted access to a non-existing download, confirming the error message in the response and the HTTP status.
5. Using an upload token to download a missing file, verifying the error message in the response and the HTTP status.
6. Using a download token to upload a file (unauthorized), checking the error message in the response and the HTTP status.
7. Mismatching token repository, ensuring the response contains the unauthorized message and the correct HTTP status.
8. Missing token, validating the unauthorized message in the response and the correct HTTP status.
9. Bad token, confirming the unauthorized message in the response and the correct HTTP status.
10. Empty body in the request, checking the response for a failed JSON body deserialization message and the correct HTTP status.
11. Missing repo in the request, verifying the response for a failed query string deserialization message and the correct HTTP status.
12. Not implemented transfer hash algorithm, checking the response for an invalid hash algo message and the correct HTTP status.
13. Not implemented transfer type, ensuring the response contains a not implemented transfer message and the correct HTTP status.

### Scenario 4: Secure Batch Endpoint Access Over HTTP and HTTPS

This test scenario focuses on accessing the batch endpoint securely over both HTTP and HTTPS, ensuring successful transfers and validating the responses under different security protocols.

1. Successful access to the batch endpoint over HTTP, using an upload token. Verify the response contains the expected transfer details and HTTP status, and ensure the connection information in the stderr includes the proxy details and HTTP/1.1 200 OK status.
2. Successful access to the batch endpoint over HTTPS, using an upload token and ignoring certificate validation (--insecure). Verify the response contains the expected transfer details and HTTP status, and ensure the connection information in the stderr includes the proxy details, SSL connection using TLS, and HTTP/1.1 200 OK status.

### Scenario 5: Secure File Transfer with Signed URLs

This test scenario involves obtaining a signed URL to upload a file, uploading the file, and then obtaining a signed URL to download the same file, verifying its integrity.

1. Get a signed URL to upload a file over HTTPS, using an upload token and ignoring certificate validation (--insecure). Verify the response contains the expected transfer details and the signed URL for the upload.
2. Upload a file ('test-upload.txt') using the obtained signed URL. Check for a successful HTTP response and upload-related details in the stderr.
3. Get a signed URL to download the uploaded file over HTTPS, using an upload token and ignoring certificate validation (--insecure). Verify the response contains the expected transfer details and the signed URL for the download.
4. Download the file using the obtained signed URL and verify that the content matches the original. Check for a successful HTTP response and download-related details in the stderr.

### Scenario 6: Proxy Minio Access with Signed URLs

This test scenario involves obtaining a signed URL to upload a file through a proxy, uploading the file, and then obtaining a signed URL to download the same file through the proxy, verifying its integrity.

1. Get a signed URL to upload a file over HTTPS through a proxy, using an upload token and ignoring certificate validation (--insecure). Verify the response contains the expected transfer details and the signed URL for the upload, with the proxy details included in the URL.
2. Upload a file ('test-upload.txt') using the obtained signed URL through the proxy. Check for a successful HTTP response and upload-related details in the stderr.
3. Get a signed URL to download the uploaded file over HTTPS through the proxy, using an upload token and ignoring certificate validation (--insecure). Verify the response contains the expected transfer details and the signed URL for the download, with the proxy details included in the URL.
4. Download the file using the obtained signed URL through the proxy and verify that the content matches the original. Check for a successful HTTP response and download-related details in the stderr, including the proxy host details.

### Scenario 7: Git LFS Integration Test

This test scenario involves configuring and testing Git LFS integration, including pushing LFS-tracked files, verifying the object ID, obtaining a signed URL to download the file, and ensuring successful file download.

1. Configure Git LFS and push an LFS-tracked file to the repository.
2. Verify that the object ID generated for the LFS-tracked file matches the expected value.
3. Manually download the file to verify its content.
4. Get a signed URL to download the LFS-tracked file over HTTP through a proxy, using a token and ignoring certificate validation (--insecure).
5. Download the LFS-tracked file using the obtained signed URL and verify that the content matches the original. Check for a successful HTTP response and download-related details in the stderr.
6. Clone the repository again and verify the presence of the LFS-tracked file in the cloned repository.

### Scenario 8: Git LFS Speed Test

This test scenario focuses on measuring the speed of Git LFS operations, including cloning a repository, tracking and adding large files, and pushing and cloning with a specific time limit.

1. Clone the repository and configure Git LFS to track '*.bin' files.
2. Generate 100 files of 1MB each and add them to the repository.
3. Commit the files and measure the time taken to push them over Git LFS. Verify that the push completes in less than 60 seconds.
4. Clone the repository again and measure the time taken to complete the clone. Verify that the clone operation completes in less than 60 seconds.
5. Verify the presence of specific files ('test1.bin', 'test27.bin', 'test83.bin') in the cloned repository.

### Scenario 9: Custom Signing Test

This test scenario involves obtaining a signed URL to upload a file with custom signer (ie not the default MinIO one). The steps include uploading the file, obtaining a download link, and ensuring successful file download using the custom signing.

1. Get a signed URL to upload a file with a randomly generated file name over HTTPS through a proxy. Verify the transfer details, including the generated object ID and custom signing parameters.
2. Upload a file with the specified content ('Test of upload.') using the obtained signed URL. Verify a successful HTTP response.
3. Obtain a download link to the uploaded file with custom signing parameters.
4. Download the file using the obtained signed URL, ensuring that the content matches the original. Check for a successful HTTP response and download-related details in the stderr.

### Scenario 10: Locks Basics

This test scenario covers the basic operations related to locks, including creating locks for specific paths, handling duplicates, listing locks, retrieving locks by ID, pagination, and deleting locks.

1. Create a lock for the path `foo/bar.bin`. Verify the lock details in the response and a successful HTTP response.
2. Attempt to create a duplicate lock for the path `foo/bar1.bin`, which should fail. Verify the error message and a conflict status (HTTP 409).
3. Create a lock for the path `foo/bar2.bin`. Verify the lock details in the response and a successful HTTP response.
4. List locks for paths `foo/bar.bin` and `foo/bar2.bin`. Verify the retrieved locks and a successful HTTP response.
5. List locks by ID, specifically for lock ID 2. Verify the retrieved lock details and a successful HTTP response.
6. Use empty search parameters for listing locks, and verify that they are ignored. Confirm the retrieved locks and a successful HTTP response.
7. Create a few more locks for pagination, and then list locks with a limit of 3, verifying the retrieved locks, pagination information, and a successful HTTP response.
8. List the next set of locks using the obtained cursor, ensuring the retrieved lock details and a successful HTTP response.
9. Delete the lock with ID 1. Verify the deleted lock details and a successful HTTP response.
10. Attempt to delete the same lock again, and verify the error message and a not found status (HTTP 404).
11. Attempt to delete a lock with an invalid ID, and verify the error message and an unprocessable entity status (HTTP 422).

### Scenario 11: Locks Multi-Users

This test scenario focuses on multi-user interactions with file locks, including creating locks, handling conflicts, listing locks, verifying locks from different users' perspectives, pagination, and force deleting locks.

1. User1 creates a lock for the path `file1`. Verify the lock details in the response and a successful HTTP response.
2. User2 attempts to create another lock for the same path `file1`, which should fail. Verify the error message and a conflict status (HTTP 409).
3. User2 creates a lock for the path `file2`. Verify the lock details in the response and a successful HTTP response.
4. List all locks from User1's perspective. Verify the retrieved locks and a successful HTTP response.
5. List all locks for verification, from both User1 and User2 perspectives. Verify the retrieved locks and a successful HTTP response.
6. Create a few more locks for pagination, and then list locks with a limit of 3 from User1's perspective. Verify the retrieved locks, pagination information, and a successful HTTP response.
7. List the next set of locks using the obtained cursor from User1's perspective, ensuring the retrieved lock details and a successful HTTP response.
8. User2 attempts to delete a lock created by User1, which should fail. Verify the error message and a forbidden status (HTTP 403).
9. User2 force deletes the lock created by User1. Verify the deleted lock details and a successful HTTP response.
10. User2 can now recreate a lock for path `file1`. Verify the lock details in the response and a successful HTTP response.

### Scenario 12: Locks Using Git LFS Client

This test scenario involves using the Git LFS client to interact with file locks, covering locking, unlocking, listing locks, and pagination.

1. Set up Git LFS and clone the testing repository.
2. Track large files with Git LFS.
3. Commit and push the changes to the repository.
4. Lock a file using the Git LFS client. Verify a successful lock operation.
5. Attempt to lock the same file again, which should fail. Verify the error message.
6. List all locks using the Git LFS client. Verify the presence of the locked file and associated details.
7. Unlock the previously locked file. Verify a successful unlock operation.
8. List locks again to ensure no locks remain.
9. Create two new files and lock them using the Git LFS client.
10. List all locks to verify the presence of the newly created locks.
11. List locks with a specific ID to ensure the correct lock details are retrieved.
12. List locks with a specific path to ensure the correct lock details are retrieved.
13. Create two more files and lock them to test pagination in the listing of locks. Verify the retrieved locks with a limit of 3.

### Scenario 13: Two Git LFS Clients Competing for a Lock

This test scenario involves simulating a scenario where two Git LFS clients attempt to acquire a lock on the same file simultaneously. The steps include:

1. Set up Git LFS and clone the testing repository on two different client instances.
2. Track large files with Git LFS on both clients.
3. Simultaneously attempt to lock the same file from both clients.
4. Verify that only one of the clients successfully acquires the lock while the other receives a failure message.
5. List locks using both clients to confirm the lock status.
6. Repeat the process with different files to ensure that locks can be successfully acquired without conflicts on different files.
7. Unlock the files and verify that the locks are released.
